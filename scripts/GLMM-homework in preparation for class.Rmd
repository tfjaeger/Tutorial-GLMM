---
title: "Generalized Linear Mixed/Multilevel Models (GLMMs)"
subtitle: "Homework in preparation for class"
author: "T. Florian Jaeger"
date: \today
geometry: margin=2cm
header-includes:
  - \usepackage{booktabs}
  - \usepackage{siunitx}
  - \usepackage{tabto}
  - \usepackage{soul}
  - \usepackage{xcolor}
  - \usepackage{placeins}
  - \usepackage{lscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
  - \setstcolor{red}
  - \usepackage{sectsty}
  - \sectionfont{\color{blue}} 
  - \subsectionfont{\color{blue}}
  - \subsubsectionfont{\color{darkgray}}
  - \usepackage{caption}
  - \usepackage{subcaption}
  - \usepackage{tikz}
  - \usepackage{url}
  - \usetikzlibrary{bayesnet}
output:
  pdf_document: 
    fig_caption: yes
    fig_width: 7
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
  fontsize: 10pt
urlcolor: blue
---

```{r set-options, include=F}
library(knitr)
opts_chunk$set(dev = 'pdf',
               comment="", 
               echo=FALSE, warning=TRUE, message=TRUE,
               cache=FALSE, 
               size="footnotesize",
               tidy.opts = list(width.cutoff = 250),
               fig.width = 8, fig.height = 4.5, fig.align = "center")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r libraries, include=FALSE}
library(tidyverse) # gotta be tidy
library(magrittr)  # pipe!
library(broom)     # working with model output
library(lme4)      # frequentist GLMMs
library(sjPlot)
library(ggthemes)   # nice themes
```

```{r constants, include=F}
chains = 4

options(
  width = 1000,
  mc.cores = min(chains, parallel::detectCores()))
```


# Reading and assignments in *preparation* of this class

Please make sure you have read Gelman \& Hill (2007, p. 301-310 in Ch 14) as well as McElreath (2019, Ch. 10.2). The latter is particularly concise and contains some beautifully clear graphs on a) the relation between different types of GLMs and b) the consequences of the link function---relating the 'original' scale (e.g., counts for the Poisson model) to the scale on which the linear predictor is fit (log-counts for the Poisson model).

Then read and *work through* this document. We will use class to go through the important concepts and to address any questions that you have about the readings or the problem sets in this document. **Please note that this document is providing R code only.** Some of the steps described here might have less direct solutions in Matlab, so it is recommended that you start early. I have, however, tried to describe each step in a way that does not depend on R or Matlab.

In this document, you will find sections labeled "Prepare for class". **Please work through those examples and write up your answers. This time please submit your answers to slack and discuss them there. Everyone should either submit an answer for each question, or discuss why they got stuck.** In addition, there are sections called "Discussion questions for class". Please think about these questions, but don't worry if you get stuck. These are some questions we can go through during class.

## Additional readings

For logistic regression another *optional* reading is James et al. (2013, Ch. 4 up to but *not* including 4.3.4). 





# Quick recap: The generalized linear model (GLM) and generalized linear mixed model (GLMM)

A generalized linear model extends the linear model (LM) to outcome variables drawn from---or *assumed* to be drawn from---the exponential family of distributions. Concise introductions are provided in Gelman & Hill (2007, Ch. 6) or MacElreath (2019, Ch. 10.2). 

## GLMs
The GLM has three components: the linear predictor ($\eta$), the link function ($g$), and the outcome distribution ($f$), as shown in Figure 1a. Building on our notation for the LM:

\begin{align}
\eta & = & X\beta \\
\mu & = & g^{-1}(\eta) \\
y & \sim & f(\mu)
\end{align}

As for the LM, $X$ is is called the *model (or design) matrix* and $\beta$ is a vector of parameter values. Note that $\eta$ and $\mu$ are fully determined by $X$ and $\beta$ (i.e., they do not introduce degrees of freedom or latent structure). The LM is a GLM for which $g$ is the identity function $I$, and f is the Normal distribution with unknown residual variance $\sigma_{resid}$:

\begin{align}
\eta & = & X\beta &  & \\
\mu & = & I^{-1}(\eta) & = \eta  = X\beta & \\
y & \sim & \mathcal{N}(\mu, \sigma_{resid}) & & \Rightarrow y \sim \mathcal{N}(X\beta, \sigma_{resid}) 
\end{align}

\begin{figure}
  \centering
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{distribution $f$}} {} {}; %
    \node[det, above=of distribution] (mu) {$\mu_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{inverse link $g^{-1}$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{Generalized linear model (GLM)}

  \caption{The three components of the GLM: the linear predictor ($X\beta$), the link function $g$, and the distribution $f$.}
\end{figure}


The exponential family of distributions---not to be confused with the exponential distribution, which is a member of the exponential family of distributions---contains such well-known members as the Normal, Bernoulli, categorical (the Bernoulli-equivalent for categorical outcomes with more than 2 levels), Poisson, Dirichlet, gamma, and inverse Wishart distributions. This provides plausible distributions for binary data (e.g., correct/incorrect), count data, ordered and unorderer categorical data, variance or sum of square data, etc. A few types of GLMs are shown in Figure 2.


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$\mathcal{N}$}} {} {}; %
    \node[latent, right=of distribution] (sigma) {$\sigma$} ; %
    \node[det, above=of distribution] (mu) {$\mu_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$I^{-1}= I$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu, sigma} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{Linear model}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$Poisson$}} {} {}; %
    \node[det, above=of distribution] (mu) {$\lambda_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$log^{-1} = exp$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{Poisson regression}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$Bernoulli$}} {} {}; %
    \node[det, above=of distribution] (mu) {$p_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$logit^{-1}$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{Logistic regression}
  \end{subfigure}
  \caption{Three different GLMs with their canonical link functions, and using typical notation (e.g., $\lambda$ instead of $\mu$ for the expected value of the Poisson model).}
\end{figure}


## Assumptions of the GLM

The GLM adjusts several of the assumptions of the LM. Foremost of all, non-normal GLMs do *not* assume that the outcome follows a normal distribution around the mean. From that it also follows that that these GLMs do *not* assume normally distributed residuals or equality of variance. In fact, many types of GLMs assume that the variance depends on the mean, and is thus systematically non-homogeneous. This is the case, for example, for the Poisson and logistic regression. If analyzing data that follow the Poisson or Bernoulli distribution, this removes the primary problem of LMs---the assumption of homogeneity of variances can lead to highly misleading results for such data (see Jaeger, 2008, for illustration). The GLM provides a way around this issue. It should be noted, however, that each specific GLM assumes a specific distribution of the data. As always, assumptions should thus be checked and, if violated, the consequences of those violations should be investigated.

The GLM inherits from the LM the assumptions of:

 + Independence of observations/errors
 + Validity/exhaustivity
 
We are also still assuming: 

 + Additivity of effects 
 + Linearity of each effects

But do so on the scale described by the link function $g$.
 
 
## GLMMs

The GLMM extends the GLM in *exactly* the same way as the linear mixed model (LMM) extends the LM: by allowing the $\beta$s to vary between levels of one or more grouping factors, while assuming that the differences between levels follow a (multivariate) Normal distribution. Grouping variables are is sometimes called *random effects*. The name grouping variable highlights the fact that the data are grouped by this variable. For example, when we have many observations from each subject (repeated measures data), the data can be thought of as grouped by subjects. 

For a GLMM with one grouping variable, this can written as follows (see Figure 3 for a side-by-side comparison of the GLM and GLMM):

\begin{align}
\label{eq:glmm:beta} \eta & = & X\beta \\
\mu & = & g^{-1}(\eta) \\
y & \sim & f(\mu) \\
\end{align}

\begin{align}
\label{eq:glmm:group} \beta & = & \beta_{population} + \beta_{group\ level}, \\
& & \beta_{group\ level} \sim \mathcal{N}(0, \Sigma) 
\end{align}

GLMMs can have more than one grouping variable. For example, for two crossed random effects:

\begin{align}
\beta & = & \beta_{population} + \beta_{group1\ level} + \beta_{group2\ level}, \\
 & & \beta_{group1\ level} \sim \mathcal{N}(0, \Sigma_{group1}) \\
 & & \beta_{group2\ level} \sim \mathcal{N}(0, \Sigma_{group2}) \\
\label{eq:glmm:perp} & & \mathcal{N}(0, \Sigma_{group1}) \perp \mathcal{N}(0, \Sigma_{group2})
\end{align}

The grouping variables can also be hierarchically organized (e.g., a national sample of students taking a college entrance exam like the SAT could be hierarchically grouped by school, county, and state). In this case, we refer to the model as a *multilevel* model (which conveniently also abbreviates to an "M").

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{distribution $f$}} {} {}; %
    \node[det, above=of distribution] (mu) {$\mu_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{inverse link $g^{-1}$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{Generalized linear model (GLM)}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_{i,j}$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$f$}} {} {}; %
    \node[det, above=of distribution] (mu) {$\mu_{i,j}$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$g^{-1}$}} {} {}; %
    \node[obs, above=of link] (X) {$x_{i,j}$} ; %
    \node[latent, right=of link] (betas) {$\beta_j$} ; %
    \factor[right=of betas] {group} {below:$\mathcal{N}$} {} {}; %
    \node[latent, above=of group] (Sigma) {$\Sigma$} ; %
    \node[latent, right=of group] (beta) {$\beta$} ; %
    \node[obs, right=of X, above=of betas] (grouplevel) {$z_j$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome)} {$N $}; %
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate2} {(mu) (distribution) (link) (betas) (X) (outcome) (grouplevel) (plate1) } {$M $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, betas, grouplevel} {link} ; %
    \edge {group} {betas} ; %
    \edge {Sigma, beta} {group} ; %
  }
  \caption{Generalized linear mixed model (GLMM)}
  \end{subfigure}
  \caption{The GLM and GLMM side by side. For the GLMM, $z_j$ is the $j$th level of the grouping variable $z$, which select which $\beta_j$ is to be chosen for the present case (i.e., $j$ here corresponds to $group\ level$ in equation \ref{eq:glmm:group}.}
\end{figure}

## Assumptions of the GLMM

The GLMM softens the independence assumption of the GLM, instead assuming *conditional independence* (conditional on the assumed random effects). This is achieved via random effects that are distributed to follow normal distributions with unknown standard deviations, centered around zero. For each grouping factor, one can further model the correlations between the random effects, in which case the by-group adjustments $\beta_{group\ level}$ to the fixed effects ($\beta_{population}$) in equation \ref{eq:glmm:group} are assumed to follow a multivariate normal distribution. Put differently, we assume that the $\beta$ vector in equation \ref{eq:glmm:beta} as being drawn from a multivariate normal distribution with mean $\beta_{population}$ and covariance matrix $\Sigma_{group}$.

For multiple random effects, we further assume that the multivariate Normal distributions for the different groups are independent of each (that's what the $\perp$ means in equation \ref{eq:glmm:perp}). All other assumptions are inherited from the GLM. 



## Writing up the results of a GLMM analysis

The write-up of a GL(M)M analysis will in many ways follow the write up of an L(M)M analysis, with a few additions. In addition to the outcome, predictors, and how we coded them, we need to clearly state what *type* of GL(M)M we're fitting. Second, since our predictors now include random effects, we need to describe those predictors, too. That is, we need to describe the *random effect structure* of the model. Like with everything else, we should also *motivate* that structure unless it is abundantly clear why this is the structure we chose. 

On a terminological note, it can become somewhat confusing to talk about random effects "for" a grouping factor (e.g., subjects) since we also need to talk about random slopes "for" a fixed effect predictor. I strongly recommend the use of "by" when talking about grouping factors, and "for" when talking about slopes. For example:

\color{lightgray}
We analyzed the trial-level data with mixed-effects logistic regression (for introduction, see Jaeger, 2008), using the function \texttt{glmer} from the \texttt{lmer} package (citation with version) of the software \texttt{R} (citation with version). We predict correct responses (1 = correct vs. 0 = incorrect) from letter size (centered), condition (deviation-coded: .5 = *crowded* vs. -.5 = *uncrowded*) and their interaction. Following standards of the field, we used the maximal random effect structure required by the design, random by-subject intercepts and slopes for condition, size, and their interaction.
\color{black}

Another difference in reporting GL(M)Ms is that the linear predictor is often on a scale that is not particularly intuitive. It is important to remember that *there is a good reason why this is the case*: many of the outcomes for which GL(M)Ms offer a better solution than LMs do not lend themselves to intuitve linear analyses on the original outcome scale (e.g., because that scale is bounded and/or reflects the result of multiple non-additive processes). I.e., the unintuitive scale on which the effects of the GLMM are expressed are a direct (inevitable) consequence of our efforts to avoid the Type I and II error inflation that would result from analyzing such data with an LM. 

Unfortunately, the use of LM, ANOVA, and $t$-tests for, e.g., count and proportion data remains common practice, although we have known for more than 70 years that this practice is problematic (for summaries directed at cognitive scientists, see Dixon, 2008; Jaeger, 2008; Johnson, 2009).

For simple factorial designs, the unintuitive scales on which the effects of the GL(M)M are expressed typically aren't much of a problem since we should accompany our analysis with plots and/or tables that summarize the relevant means anyway. Those figures/tables tend to provide an intuitive summary of the data. However, if we do need to somehow translate our effects into more intuitive scales, there are a number of ways to do so. See e.g., the "divide by four rule" for mean proportions close to .5, described in Gelman and Hill, 2007. Or take the fact that we can describe additive effects on log counts in terms of multiplicative effects on counts (similarly, we can describe effects additive effects on log-odds in terms of multiplicative effects on odds). If push comes to shove, we can always describe what the predicted outcome is at meaningful values of our predictor (e.g., the 5th and 95th quantile of a continous predictor), and those point predictions can be translated to the scale of the original outcome: simply plug those predictor values into the linear predictor, apply the inverse link function, and you have the predicted mean.








# Working through a real example

The goal of this homework example is to familiarize yourself with the use of logistic and mixed-effects logistic regression in a real-life research context. Work through the examples below with the goal to arrive at a write-up of a result section that addresses the two working hypotheses introduced below (H1 and H2).

## Research background
Crowding is a visual phenomenon that has puzzled scientists for decades; an object in isolation can be perceived without problems, yet surrounding it with similar objects makes it harder to see. While crowding has been studied extensively in the visual periphery, humans normally orient objects in their center of gaze, the high-acuity region of the retina called the foveola. While the foveola is less than 1.5mm wide (or ~1 visual deg2), it contains more cones than rest of the retina combined. Human’s ability to actively perceive the visual world relies heavily on not only the foveola itself, but also how and where the eye is positioned. The few studies that have examined crowding within foveal vision have produced contradictory results. Some reasons for these discrepancies include using relatively large stimuli, a small number of participants, abnormal stimuli presentation, and having indefinite stimulus presentation times with no eye tracking. More recent research, however, has highlighted the importance of precise eye tracking due to the eye’s constant movement during even fixation. These small and constant movements of the eye, called fixational eye movements (FEMs), are beneficial or both high acuity vision, as well as daily tasks such as reading and face recognition. FEM’s have never been examined in the context of crowding, and it remains unknown how individuals in previous crowding studies directed their foveola over stimuli, or even maintained fixation.

## Research goals
The goals of this research are to (1) investigate the effect of crowding within the foveola, and (2) examine if and how fixational eye movements influence crowding at this scale. Based on previous research, we hypothesize that crowding will be detrimental to foveal vision, as it is in peripheral vision, but on a finer scale. Further, based on the recent findings that FEMs are beneficial for high-acuity vision, I expect a relationship between FEMs and the strength of crowding within the foveola, with larger and less precise FEMs increasing the negative effects visual crowding.

## Research hypothesis to be tested *in this tutorial*
Here, your goal is to test whether crowding---operationalized through two crowding conditions described below---affects the accuracy of number recognition. You will assess this while controlling for the size of the letters/numbers on the screen, as stimulus size is known to have large effects on recognition accuracy. We test two working hypotheses:

 * (H1) Crowding will reduce recognition accuracy (after controlling for letter size)
 * (H2) Letter size will have an increased effect in the more crowded displays.


## Data

For this tutorial we are continuing to use Ashley Clark's data from her experiment on visual crowding effects on foveal processing. \textbf{Do not share this data with Ashley's permission. Thank you.}

### Methods
Studying FEMs during visual crowding within the foveola requires high-precision eye tracking and accuracy in localizing the center of gaze. Current video eye trackers do not have the required spatial precision, as the error of gaze localization is as large as the foveola itself. However, by using a custom built state-of-the-art eye tracking system with arcminute precision, we will be able to examine exactly how FEMs contribute to crowding within the foveola. Stimuli consist of a number-font designed specifically for studying crowding in the fovea, as it allows for recognition even when numbers are closer together than traditional optotypes used in other crowding studies.6 Two conditions will be examined, the uncrowded (where a single number is presented), and the crowded (where the same size number is presented, but with four surrounding numbers). The size of the number and spacing between the numbers in the crowded condition change throughout the experiment based on the subject’s performance using an adaptive procedure. The stimuli presented will vary in size, ranging from 0.5 arcminutes to 4 arcminutes in width. To determine the number-width threshold, we use a standard psychophysics procedure measuring the width of the stimulus at which a subject performs above chance level. 

### Overview

Subject-level variables include:

 * Subject
 * Condition: "crowded" or "uncrowded"
 * Threshold: threshold inferred from a previous Weibull model fit to the subjects trial-level data
 * DiffusionConstant
 * Span
 * Area
 * Curvature
 * Speed

Size-level variables include:

 * Size: the width (or strokewidth) of the stimulus during that group of trials.
 * Performance: What the overall performance for the size stimulus was.
 
Trial-level variables:

 * Response: What number the subject guessed.
 * Answer: What the number presented on the screen was.
 * Correct: Whether the response was correct or not (combining information from Response and Answer)
 * Response Time: response time of subject. Note* subjects were not told to response as quickly as possible during experiment.
 * Traces: the x and y traces of each trial in this size stimulus group.
 * Trial Curvature: Same as curvature above, but for each individual trial.
 * Trial Speed: Same as speed above, but for each individual trial. 

For the present purpose, I'm renaming "Crowded" as "Condition", "Answer" as "ResponseExpected", "Correct" to "ResponseCorrect". I'll also prefix all subject-level variables with "Subject" and remove the "Trial" prefix that is used for some (but not all) of the trial-level variables. Finally, since performance refers to the average performance for a specific letter size, I change it to "Size.AvgPerformance". I then order the column from the least quickly varying (across rows) to the most quickly varying.

```{r load data, message=F}
d = read_csv("../data/data_ClarkCrowding_TrialLevel.csv") 
d %<>%
  droplevels() %>%
  rename(
    Condition = Crowded,
    Threshold.Subj = Threshold,
    DiffusionConstant.Subj = DiffusionConstant,
    Span.Subj = Span,
    Area.Subj = Area,
    Curvature.Subj = Curvature,
    Speed.Subj = Speed,
    Size = Size,
    Size.AvgPerformance = Performance,
    ResponseExpected = Answer,
    ResponseCorrect = Correct,
    Curvature = TrialCurvature,
    Speed = TrialSpeed,
    Span = TrialSpan
    ) %>%
  mutate(Condition = factor(ifelse(Condition == 0, "uncrowded", "crowded"), 
                            levels = c("uncrowded", "crowded"))) %>%
  select(Subject, Condition, Threshold.Subj, DiffusionConstant.Subj, Area.Subj, Span.Subj, Speed.Subj, everything(), Span, Speed, Curvature) %>%
  mutate_at(c("Subject"), factor)

str(d)
```

### Available data formats

The git repository contains the data in three formats: a .mat file, and .Rdata file with a single tibble/data.frame object (d), and a .csv file that contains all information except the X and Y traces.





## GLM (logistic regression)

We first deviation-code the crowdedness condition:

```{r, echo=T}
levels(d$Condition)
contrasts(d$Condition) = cbind("Crowded.vs.Uncrowded" = c(-.5, .5))

center = function(x) { return(x - mean(x)) }
```

Now we analyze the data from one subject (Subject 4) in an ordinary non-mixed logistic regression (we center Size within the model formula because that makes plotting of the data on the original scale of letter size easier for the *R* function below):

```{r, echo=T}
l = glm(
  ResponseCorrect ~ 1 + center(Size) + Condition + center(Size):Condition,
  data = d %>% 
    filter(Subject == "4"),
  family = binomial)

summary(l)
```

We now plot the predictions from this GLM. The dashed lines indicate the expected chance accuracy under guessing (25% since the experiment employed four different target numbers, all of which occurred equally often across trials, and subjects had to respond which of the four numbers they saw):

```{r, message=F}
p.common =  
  list(geom_hline(yintercept = .25, color = "black", linetype = 2), 
       scale_y_continuous(
         "Probability of correct response"),
       theme_fivethirtyeight())

p.common.x =  
  append(
    p.common,
    list(
       scale_x_continuous(
         "Letter size"),
       coord_trans(
         ylim = c(0,1))))

plot_model(
  l, 
  type = "eff",
  terms = c("Size", "Condition"),
  show.data = T, 
  jitter = .025) +
  p.common.x

plot_model(
  l, 
  type = "eff",
  show.data = T, 
  jitter = .025)[[2]] +
  p.common 
```

### Prepare for class 
 
 1. In your own words, describe in 1-2 sentences the effect of size (for this subject). Is it significant? Is it positive or negative? What does that mean intuitively (describe the effect on the outcome).
 1. Do the same for the effect of condition. Use the terms crowded and uncrowded. What is the predicted difference in log-odds of an accurate answer between the two conditions (for this subject). 
 1. What's the conceptual interpretation of the interaction for this subject? Try to describe it in your own words.
 1. What are your conclusions with regard to H1 and H2 for this subject?
 1. For the uncrowded condition, how would you go from this to calculate the required letter size to achieve 62.5\% threshold accuracy? 
 
### Discussion questions for class

 6. Do you see any issues with this model? (compare the model predictions to the expected 25% under random guessing)
 1. What causes these issues? I.e., what assumption of the model might we need to question?

## GLMM (mixed-effects logistic regression)

The we fit the mixed-effects logistic regression with the full random effect structure required by the design:

```{r, echo=T}
m = glmer(
  ResponseCorrect ~ 1 + center(Size) + Condition + center(Size):Condition + 
    (1 + center(Size) + Condition + center(Size):Condition | Subject),
  data = d,
  control = glmerControl(
    optimizer = c("bobyqa"),
    optCtrl = list(
      npt = 10,
      maxfun = 2e6)),
  family = binomial)

summary(m)
```

We cover convergence problems and warnings of possible singular fits below. For now, let's ignore this warning and plot the model's predictions:

```{r, message=F, warning=F, error=F}
# For plotting with plot_model, I'm reparameterizing the model
mp = glmer(
  ResponseCorrect ~ 1 + Size + Condition + Size:Condition + 
    (1 + Size + Condition + Size:Condition | Subject),
  data = d,
  family = binomial)

plot_model(
  mp,
  type = "eff",
  show.data = T, 
  jitter = .025)[[1]] + 
  p.common.x

plot_model(
  mp,
  type = "eff",
  show.data = T,
  jitter = .025)[[2]] + 
  p.common
```


### Prepare for class 
 
 1. Drawing on what you've learned about LMs, GLMs, and GLMMs, write a result section for the above model, and submit it on Slack prior to the class. (The model is exactly the one described in the method write-up at the end of Section 2).
 2. How could you assess whether the effect of condition is fully mediated (subsumed) by effect of crowded on the *speed* of eye movements, which then causes the effect on accuracy? I.e., how would you test the hypothesis that the causal model for your data is crowdedness of display $\rightarrow$ speed of eye movements $\rightarrow$ accuracy (indirect causation), rather than crowdedness of display $\rightarrow$ accuracy (direct causation)? Describe what you'd want to do in your own words, or try it out (in R, for example, you can compare glmer fits with the anova() function in just the same way that you can compare lm() or glm() fits).



# Using the GLMM to obtain subject-specific estimate

As it is a GL*M*M, we can also obtain estimates of the individual differences in the effects (at least for any predictor for which we were able to fit random slopes by subject). These estimates can be used to obtain subject-specific psychometric thresholds under the *partial pooling* assumption of mixed models. 

## Why use GLMMs to obtain subject-specific estimate? The benefits of partial pooling

You might wonder **why we would want to use a GLMM to estimate subject-specific thresholds, rather than individual GLMs fit separately to each subject's data.** There is actually something rather appealing about the GLMM approach: it takes into account *all* data while estimating each subject-specific parameters. Essentially, **the assumption of normally distributed individual differences acts as a *regularizing prior* that 'shrinks' the subject-specific estimates towards the population mean, thereby reducing the probability of overfitting the model(s) to the data.** Such shrinkage based on the overall mean is generally a good feature for prediction. It essentially trades off fit for the sample (reducing it) against likely fit against as of yet unseen data (increasing predictive accuracy). McElreath (2019) summarizes this very nicely for GLMMs (e.g., on p. 419). Shrinkage is also discussed in length in Gelman & Hill (2007, Section 12.3). I encourage you to read those sections. 

The benefit of shrinkage to the population mean is particularly noteworthy when we have little data per subject but a lot of subjects. It does not come for free, however: if the assumption of normally distributed individual differences is wrong it can create bias. For the type of data we tend to analyze in the psychological sciences the normality assumption about the individual differences is usually sufficiently close to the truth (at least for our typical population of college students; this might differ if one works with highly heterogeneous patient populations). 

## An example

The following plot shows the posterior distribution of by-subject differences in each of the four coefficients of the model fit above:

```{r, fig.width=10}
plot_model(
  m,
  type = "re", pred.type = "re", 
  transform = NULL) + 
  theme_fivethirtyeight()
```
As is evidence from these plots, the GLMM returns a *distribution* over possible subject-specific adjustment in the intercept and effects. As a *point estimate* of the subject-specific adjustment, we typically use the so-called best unbiased linear predictors (BLUPs)---the posterior *mode* of the random effects for each subjects (the value with the highest estimated density. Whereas the points in the above plot reflect the mean of the by-subject effect estimated for each subject, the BLUPs are the mode of that distribution. Typically, these two values will be closely related. Take, for example, the BLUP for subject 2's intercept (.7317...) and compare it to the plot (second to last row, last column).

```{r}
ranef(m)
```

### Prepare for class 
 
 1. What intercept does this model predict for Subject 9? 
 1. Is that intercept smaller or larger than the predicted intercept for subject 8? Is it smaller or larger than the predicted population intercept?
 1. What are your conclusions with regard to H1 and H2?

### Discussion questions for class

 4. Calculate the threshold size for Subject 2 in the uncrowded condition?
 1. How much does this threshold size differ from that in the crowded condition?
 1. What intercept does the model predict for a novel Subject that was not part of the data we fit the model to?
 
 
 
 

# Issues during GLMM fitting

## Convergence failures
In particular for full random effect structures, GLMM fitting might not converge, as indicated by the error message. This will trigger a convergence error in R. **You cannot rely on the output of models that have not converged. Do not ignore this error message.**

When a model fails to converge, we can try to increase the number of iterations that the fitting algorithm uses to find the best-fitting parameters. For example, in R we might invest additional compute time to achieve more accurate computation, and refit the model. 

If that does not work, we can simplify the random effect structure by removing the most complex terms. We start by removing the random correlations. In R, we can use the shorthand "||" instead of "|" to indicate that we are willing to assume that the correlations are between the random variance are zero. If that still does not yield convergence, we remove the random by-subject slopes for the interaction, etc. I.e., we reduce the model step by step:

\begin{align}
ResponseCorrect ~ 1 + Size * Condition + (1 + Size * Condition | Subject) \\
ResponseCorrect ~ 1 + Size * Condition + (1 + Size * Condition || Subject) \\
ResponseCorrect ~ 1 + Size * Condition + (1 + Size + Condition || Subject) \\
etc.
\end{align}


## Singular fits
Even when a model converges, it might reflect a singular fit (R will print a *warning* if that is the case). Essentially, this means that one of the variances of the random effects might be zero, or that one of the correlations between the random effects might be -1 or 1. From the R help file on \texttt{isSingular}: 

\begin{quote}Complex mixed-effect models (i.e., those with a large number of variance-covariance parameters) frequently result in singular fits, i.e. estimated variance-covariance matrices with less than full rank. Less technically, this means that some "dimensions" of the variance-covariance matrix have been estimated as exactly zero. For scalar random effects such as intercept-only models, or 2-dimensional random effects such as intercept+slope models, singularity is relatively easy to detect because it leads to random-effect variance estimates of (nearly) zero, or estimates of correlations that are (almost) exactly -1 or 1. However, for more complex models (variance-covariance matrices of dimension >=3) singularity can be hard to detect; models can often be singular without any of their individual variances being close to zero or correlations being close to +/-1. 
... 

While singular models are statistically well defined (it is theoretically sensible for the true maximum likelihood estimate to correspond to a singular fit), there are real concerns that (1) singular fits correspond to overfitted models that may have poor power; (2) chances of numerical problems and mis-convergence are higher for singular models (e.g. it may be computationally difficult to compute profile confidence intervals for such models); (3) standard inferential procedures such as Wald statistics and likelihood ratio tests may be inappropriate.
\end{quote}

While singular fits are not technically an error, we might want to check whether the conclusions we would draw from this analysis would hold under a slightly simpler model that avoids the singularity. This would be achieved by following the same stepwise simpiflication of the random effect structure used above when the model failed to converge. Alternatively, and perhaps to be preferred, we could employ a Bayesian approach, in which case weakly regularizing priors are often sufficient to help to model converge.







# Session info
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
