---
title: "Psychometric models"
subtitle: "A brief applied overview"
author: "T. Florian Jaeger"
date: \today
geometry: margin=2cm
header-includes:
  - \usepackage{booktabs}
  - \usepackage{siunitx}
  - \usepackage{tabto}
  - \usepackage{soul}
  - \usepackage{xcolor}
  - \usepackage{placeins}
  - \usepackage{lscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
  - \setstcolor{red}
  - \usepackage{sectsty}
  - \sectionfont{\color{blue}} 
  - \subsectionfont{\color{blue}}
  - \subsubsectionfont{\color{darkgray}}
  - \usepackage{caption}
  - \usepackage{subcaption}
  - \usepackage{tikz}
  - \usepackage{url}
  - \usetikzlibrary{bayesnet}
output:
  pdf_document: 
    fig_caption: yes
    fig_width: 7
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
always_allow_html: true
urlcolor: blue
---

```{r set-options, include=F}
library(knitr)
opts_chunk$set(dev = 'pdf',
               comment="", 
               echo=FALSE, warning=TRUE, message=TRUE,
               cache=FALSE, 
               size="footnotesize",
               tidy.opts = list(width.cutoff = 250),
               fig.width = 8, fig.height = 4.5, fig.align = "center")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r libraries, include=FALSE}
library(tidyverse) # gotta be tidy
library(magrittr)  # pipe!
library(broom)     # working with model output
library(brms)      # Bayesian GLMMs and NLMMs
library(tidybayes) # working with posterior samples of Bayesian models

library(ggthemes)  # cool themes!
library(scales)    # to plot predictions on original scale of predictor
```

```{r constants, include=F}
chains = 4

options(
  width = 1000,
  mc.cores = min(chains, parallel::detectCores()))
```


# Goals of this tutorial
This tutorial aims to illustrate the relation between psychometric models (as used in psychophysics) and generalized linear models (GLMs) / generalized linear models (GLMMs). It's best to read it *after* reading the accompanying GL(M)M tutorial within the same git repository. 

Psychometric models aim infer the 'threshold' and 'slope' of a categorization/recognition function along one or more stimulus dimensions (e.g., visual contrast, intensity, size, etc.). One challenge in doing so is that the exact function is unknown, though plausible candidates---such as the Weibull, Gumbel, logistic, cumulative Gaussian, etc.---exist ([quick side-by-side of these functions](http://psignifit.sourceforge.net/PSYCHOMETRICFUNCTIONS.html)). Another challenge is that the estimates of the threshold and slope parameters can be affected (and biased) if attentional lapses are not considered. 

```{r load data, message=F}
d = read_csv("../data/data_ClarkCrowding_TrialLevel.csv") 
d %<>%
  na.omit() %>%
  droplevels() %>%
  rename(
    Condition = Crowded,
    Threshold.Subj = Threshold,
    DiffusionConstant.Subj = DiffusionConstant,
    Span.Subj = Span,
    Area.Subj = Area,
    Curvature.Subj = Curvature,
    Speed.Subj = Speed,
    Size = Size,
    Size.AvgPerformance = Performance,
    ResponseExpected = Answer,
    ResponseCorrect = Correct,
    Curvature = TrialCurvature,
    Speed = TrialSpeed,
    Span = TrialSpan
    ) %>%
  mutate(Condition = factor(ifelse(Condition == 0, "uncrowded", "crowded"), 
                            levels = c("uncrowded", "crowded"))) %>%
  select(Subject, Condition, Threshold.Subj, DiffusionConstant.Subj, Area.Subj, Span.Subj, Speed.Subj, everything(), Span, Speed, Curvature) %>%
  mutate_at(c("Subject"), factor)

str(d)
```


# Readings and other materials

To learn more about psychometric models, you might also find Gilchrist et al. (2005) and Wichmann and Hill (2001a, b) helpful (both in *Perception & Psychophysics*). Prins (2013, *Journal of Vision*) provides a counterpoint to the solution proposed in Wichmann and Hill (2001). All of these papers are relatively heavy on math. 

Luckily, there is a wealth of information out there, including introductory walk-throughs and powerful animated demonstrations. Here are some walk-through demonstrations (thanks to Martina Poletti, who pointed me to them):

 * \url{http://www.dlinares.org/lapsesquickpsy.html} (partially replicating Wichmann’s point about biases, but also replicating Prins’s failure to replicate Wichmann’s proposed solution)
 * \url{http://www.palamedestoolbox.org/understandingfitting.html} (beautiful animations and visualizations explaining the fitting process, and the relation between lapse, threshold, and slope; really drives home the point that these three parameters form a joint distribution for which we’re trying to find the set of values that maximize the likelihood of the observed outcomes). Also goes through the Prins and Palamedes papers, and ends with a list of tips.
 * \url{http://www.palamedestoolbox.org/weibullandfriends.html} (Nice explanation of the psychometric-specific jargon and naming of models; e.g., Gumbel vs. Weibull, a matter of log-transforming the predictor)
 
Some toolboxes/libraries for psychometric models:

 *  Matlab: 
   * [psignifit/](https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/neuronale-informationsverarbeitung/research/software/psignifit/)
 * R: 
   * [quickpsy](http://dlinares.org/quickpsy.html)
   * [psyphy](https://cran.r-project.org/web/packages/psyphy/index.html) include GLM-based psychometric model fitting, lapse models, and a variety of psychometric models (incl. cumulative Gaussian)
   * [modelfree](https://personalpages.manchester.ac.uk/staff/d.h.foster/software-modelfree/latest/home): non-parametric estimation of psychometric functions.
   * [brms](https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf) can in principle fit outcomes that follow a Bernoulli, Weibull, or Generalized Extreme Value Distribution. This should cover the logistic, Weibull, Gumbel, and Generalized Extreme Value model. It's not yet clear to me whether \texttt{brms} would also be able to fit the cumulative Gaussian model. In any case though, at least the mixture specification is only available if the response part of the model is defined over real numbers (like the lapse part of the model). This is not, for example, the case for the Weibull (and hence Gumbel) model. The main appeal of \texttt{brms} in my view is that it's part of a more general framework of Bayesian model estimation and thus access to the full posterior distribution of all parameters (e.g., via \texttt{tidybayes}). [Summary of distributional families that can be specified in \texttt{brms}](https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html).
   
Further readings:

 * Abrahamyan et al. (2016) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4922170/ (on adaptive procedures)
 * Jigo & Carrasco (2020) https://jov.arvojournals.org/article.aspx?articleid=2770148 (on exogenous and endogenous attention and their effects on the psychometric function)




# Psychometric functions

In psychometric modeling, we predict subjects' responses from a stimulus value. A number of different predictive models are frequently used, with choices varying between labs, based on goodness of fit, or field-specific conventions. Of relevance to this class, all of these models fall into the class of non-linear models (NLM) and some are also generalized linear models (GLMs). That is, psychometric functions/modeling is partly a subset of the type of models we cover in this class, and partly closely related. The goal of this section is to illustrate the relation between GL(M)Ms and psychometric functions a bit further, so that your understanding of GL(M)Ms can also inform your analysis choices for psychometric data.

Four commonly used psychometric functions include the cumulative Gaussian, logistic, Weibull, and Gumble (Generalized Extreme Value distribution a.k.a. log Weibull). For formal introductions, the relation between the different functions, and their relative trade-offs, see also the readings listed at the top of this tutorial.

Any of these functions for the stimulus-driven model can be expanded to account for the proportion of trials on which the subject responds independent of the stimulus (e.g., because the subject experienced an attentional lapse) and optionally the bias (or guessing rate) on those lapsing trials. We'll start with some more background on the lapsing model.

# Lapsing model

The lapse model is essentially a mixture model with two components. One component describes the responses that depend on the stimulus (e.g,. the logistic model discussed above), as a function of two parameters $\alpha$ and $\beta$. The specific interpretation of these two parameters depends on the psychometric function, but each of the functions can be parameterized such that $\alpha$ is some targeted threshold performance, and $\beta$ is the 'slope' at that threshold. The second component if the mixture model describes responses that are *in*dependent of the stimulus (i.e., the bias term $\gamma$). The weight of the second component is the lapse rate ($\lambda$):

\begin{align}
p(response | stimulus, \alpha, \beta, lapse, bias) = (1-lapse) * p(response | stimulus, \alpha, \beta) + lapse * p(response | bias)
\end{align}

which is also sometimes written as 

\begin{align}
p(correct\ response | stimulus, \alpha, \beta, \lambda, \gamma) = (1- \lambda - \gamma) * p(correct\ response | stimulus, \alpha, \beta) + \gamma
\end{align}

where $p(correct response | stimulus, \alpha, \beta)$ could be, for example, a logistic GLM, or any of the other common psychometric functions. The resulting model is *not* a GLM anymore (but it can still be fit with maximum likelihood fitting). **To develop an intuition** about what the lapse rate ($\lambda$) and bias parameters ($\gamma$) do, check out the interactive website at \url{https://hlplab.shinyapps.io/BayesianIdentificationAndDiscrimination/}. The site's first tab describes category identification (categorization) and perceptual discrimination for two Gaussian categories by an ideal observer. We'll focus on the "Ideal identification" plot (right side, in the middle of the lower half of the screen) and how it changes if you changes as a function of the rate of attentional lapsing (top left) and bias (unclick "Prior as bias" and then try out different biases). The ideal categorization function between two Gaussian categories turns out to be a logistic function (with linear and quadratic stimulus effects)---i.e., one of the psychometric functions mentioned above (and a GLM). So the effects of lapse rate and bias that you see on this site give you an initial idea of how these parameters can affect the fit of psychometric functions.

# Applying a lapsing logistic GLMM to Ashley's data

Were is an example in R using the library \texttt{brms} for Bayesian regression modeling, which---among many other things---provides efficient fitting of non-linear models. \texttt{brms} converts GL(M)Ms, GA(M)Ms, NL(M)Ms, and a number of other model types into \texttt{stan} code. \texttt{stan} is a model specification language with interfaces to Matlab, R, Python and other languages. It comes with an efficient sampler. \texttt{stan} programs are compiled into C++ code, sampled from, and the resulting posterior samples of the fitted model are returned ... in this case to R's \texttt{brms} functions. Using a Bayesian approach has a number of upsides, one of which is that the straightforwardness of obtaining (Bayesian) confidence intervals for any of the parameters in the model.

## Case study: understanding the consequences of assumptions about attentional lapses

As a first illustration, here is the formula describing this model for the case of non-hierarchical data (data from a single subject). \texttt{brms} also allows us a more elegant way to formulate this model directly as a mixture model (see replies to \url{https://discourse.mc-stan.org/t/fitting-lapsing-psychometric-functions-with-brms/5762/2}) but the following non-linear model syntax is perhaps more transparent for the present purpose:

```{r, echo=T}
# Defining a brms formula for the non-linear model. It has three components:
# the lapse rate, the guess (bias), and the linear predictor eta. Each of these
# components can be described by a linear predictor. For this psychometric 
# model we describing eta as the linear combination of the intercept and the 
# effect of the stimulus. The other two parameters are just described by only
# their respective 'intercepts'.
BF <- brmsformula(
  ResponseCorrect ~ guess + (1-guess-lapse) * inv_logit(eta),
  eta ~ 1 + Size,
  guess ~ 1,
  lapse ~ 1, 
  family = bernoulli(link="identity"),
  nl = TRUE
) 
```

For non-linear models, it can be important to incorporate constraints on the parameters, or any knowledge we have about plausible values for the parameters. Since we are taking a Bayesian approach here, this is achieved through the definition of priors. Throughout this tutorial, we only use very weakly regularizing priors---i.e., priors that do not bias the coefficient values in either direction but that 'pull' them closer to zero (following recommendations from \url{https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations}). In effect, these priors implement Occam's razor: unless there is sufficient evidence in the data itself, we assume that the null hypothesis is true for all of our parameters. We can also define lower and upper bounds (lb and ub in the code) for, e.g., the lapse rate and bias parameters, but we first fit this model without any constraint on the lapse rate and bias:

```{r, echo=T}
# Define weakly regularizing prior, including lower (lb) and upper bounds (ub)
# for the lapse and guess parameters
my.priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", nlpar = "eta"),
  prior(beta(1, 1), nlpar = "lapse", lb = 0, ub = 1),
  prior(beta(1, 1), nlpar = "guess", lb = 0, ub = 1)
)
```

So that the priors are on the right 'scale', we follow (Gelman et al., 2008), and standardize the continuous predictors in the model. As is typical for analyses of experimental data with two balanced conditions, we deviation/sum/abova/effect-code the condition variable, with the 'treatment' receiving the positive predictor value:

```{r, echo=T}
# We store the mean and sd of Size so that we can later transform the model's predictions back 
# onto the scale of original Size predictor
Size.mu = mean(d$Size)
Size.sd = sd(d$Size)

# Standardize Size and make sure order of levels for Condition is as intended
d %<>%
    mutate(
      Condition = factor(Condition, levels = c("uncrowded", "crowded")),
      Size = (Size - mean(Size)) / (2 * sd(Size)))

# Sum-code condition
contrasts(d$Condition) = cbind("Crowded.vs.Uncrowded" = c(-.5,.5))
```

Let's fit this model to the data from Subject 1. 

```{r, message=F, warning=T, error=F}
fit.1 <- brm(
  BF,
  data = d %>%
    filter(Subject == "1"),
  control = list(adapt_delta = 0.999),
  iter = 8000,
  thin = 5,
  prior = my.priors,
  file = "../models/subject-lapse-bias"
)

summary(fit.1)
plot(fit.1)
p = plot(conditional_effects(fit.1), 
         plot = F,
         points = T, 
         point_args = list(alpha = .05, height = .025, width = .025),
         theme = theme_fivethirtyeight())[[1]] 

unstandardize = function(x) { x * Size.sd + Size.mu }
standardize = function(x) { (x - Size.mu) / Size.sd }

p.common =  
  list(geom_hline(yintercept = .25, color = "black", linetype = 2),
       scale_x_continuous(
         "Letter size"), 
       scale_y_continuous(
         "Probability of correct response"),
       coord_trans(
         x = trans_new(
           "unstandardize",
           transform = "unstandardize",
           inverse = "standardize")
       ))

p + p.common
```

This model fit does not converge, and a look at the posterior samples suggests why. This model has the typical hallmarks of unidentifiability with two solutions emerging (symmetrical around 0 log-odds for the logistic part of the model; symmetrica around .5 for the guess and lapse rate, which are expressed on the scale of proportions).

We refit the model while constraining the guess and lapse rate to be less than .5, i.e., less than half of the trials are attentional lapses. This is a very weak assumption. 

```{r, echo=T}
my.priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", nlpar = "eta"),
  prior(beta(1, 1), nlpar = "lapse", lb = 0, ub = .5),
  prior(beta(1, 1), nlpar = "guess", lb = 0, ub = .5)
)
```

Let's refit the model with these revised priors to the data from Subject 1. This model converges, shows no signs of multimodality in the posterior, and reveals an effect of letter size (the 95\% credible interval does not include 0). The predictions of the model also make sense (e.g., that it converges against chance at 25\%). It is, however, worth noting that there is ** *substantial* uncertainty about the lapse rate and bias terms**. This makes sense: although we have a lot of trials for each subject, we have very little information about the effect of size on the subject's responses since we're only testing at a few points along the size continuum. Additionally, psychometric designs tend to test mostly in the mid-performane part of the continuum. This is the case here, too: note that most of the data is in the middle of this subject's data. These common properties of psychometric designs makes it difficult to reliably distinguish between the effect of stimulus and effects of lapsing.

```{r, message=F, warning=F, error=F}
fit.2 <- brm(
  BF,
  data = d %>%
    filter(Subject == "1"),
    control = list(adapt_delta = 0.999),
  iter = 8000,
  thin = 5,
  prior = my.priors,
  file = "../models/subject-lapse-bias-constrained"
)

summary(fit.2)
plot(fit.2)
p = plot(conditional_effects(fit.2), 
         plot = F,
         points = T, 
         point_args = list(alpha = .05, height = .025, width = .025),
         theme = theme_fivethirtyeight())[[1]]
p + p.common
```
What is often done in this type of research is to fix the bias term to the chance level, which is known (here it is .25). Under this simplifying assumption, we can thus rewrite and refit the model. This increases the certainty about the lapse rate parameter, but still leaves substantial uncertainty. This is not a rare scenario: for psychometric data with only a few measurement points along the mid-performance range of the stimulus, we can often not distinguish between effects of attentional lapses and the effect of the stimulus. This is worth noting since higher lapse rates in a model like this one will result in steeper (larger) slope estimates, and will also affect our threshold estimate.

```{r, echo=T}
BF.lapse <- brmsformula(
  ResponseCorrect ~ .25 + (.75-lapse) * inv_logit(eta),
  eta ~ 1 + Size,
  lapse ~ 1, 
  family = bernoulli(link="identity"),
  nl = TRUE
)

my.priors.lapse <- c(
  prior(student_t(3, 0, 2.5), class = "b", nlpar = "eta"),
  prior(beta(1, 1), nlpar = "lapse", lb = 0, ub = .5)
)
```

```{r, message=F, warning=T, error=F}
fit.lapse.1 <- brm(
  BF.lapse,
  data = d %>%
    filter(Subject == "1"),
    control = list(adapt_delta = 0.999),
  iter = 8000,
  thin = 5,
  prior = my.priors.lapse,
  file = "../models/subject-lapse-constrained"
)

summary(fit.lapse.1)
p = plot(conditional_effects(fit.lapse.1), 
         plot = F,
         points = T, 
         point_args = list(alpha = .05, height = .025, width = .025),
         theme = theme_fivethirtyeight())[[1]]
p + p.common
```

## Determining the subject-specific threshold

From a model like that fit in the previous section, we can obtain both naive and lapse-corrected performance thresholds. For lapse-corrected threshold, we need to solve the logistic part of the model for the desired threshold. Note that this is an approximate estimate. To get a better estimate, we should marginalize over all posterior samples. This will not necessarily the same as using the (mean) estimates for both the intercept and slope since the posterior distributions of the intercept and slope might be correlated. 

\begin{align}
logit(threshold) & = & \alpha + \beta * Size 
\end{align}

For example, for a threshold of .625, we set:

\begin{align}
logit(.625) & = & \alpha + \beta * Size & \Rightarrow \\
0.5108256 & = & 1.04 + 2.00 * Size & \Leftrightarrow \\
-0.2645872 & = & Size
\end{align}

```{r, warning=F}
p + 
  p.common +
  geom_segment(x = -0.2645872, xend = -0.2645872, y = 0, yend = .625, color = "red", inherit.aes = F)
```

## Combining the data from all subjects

One appeal of approaching psychometric data from the perspective of GLMMs is that we can apply the same random effect approach as in GLMMs for the lapse rate model (which then falls into the class of NLMMs). At this point, I am switching to the mixture formulation of the model as the NLMM formulation didn't converge (2 divergent transitions even with typical priors, thinning, etc.), and the mixture formulation is computationally more effective.

Now that we're using a bit more data (all 6500 or so trials), the model will take a moment to fit. On my machine it took about 30 minutes. 

```{r}
my.priors.lapse.mixture <- c(
  prior(student_t(3, 0, 2.5), class = "b", dpar = mu2),
  prior(cauchy(0,2.5), class = "sd", dpar = mu2)
)

fit.lapse.mixed.mixture <- brm(
  bf(ResponseCorrect ~ 1, 
     mu1 ~ 0 + offset(qlogis(.25)),
     mu2 ~ 1 + Size * Condition + (1 + Size * Condition | Subject), 
     theta1 ~ 1 + (1 | Subject)),
  data = d, 
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = "none"),
  init = 0,
  control = list(adapt_delta = 0.999),
  iter = 2000,
  thin = 1,
  prior = my.priors.lapse.mixture,
  file = "../models/subject-lapse-mixed-mixture")

summary(fit.lapse.mixed.mixture)
hypothesis(fit.lapse.mixed.mixture, "mu2_Size > 0")
hypothesis(fit.lapse.mixed.mixture, "mu2_ConditionCrowded.vs.Uncrowded < 0")
hypothesis(fit.lapse.mixed.mixture, "mu2_Size:ConditionCrowded.vs.Uncrowded < 0")
```

The following plots shows the predictions for each of 100 random posterior samples from each subjects (each curve corresponds to one posterior sample). The solid lines shows the predictions based on the *means* of the posterior samples. This line does not have to fall in the center of the other lines is that the three parameters of the model can be correlated (within and across participants). Taking the mean, rather than marginalizing over the entire posterior distribution, ignores those correlations (but is a *lot* faster to compute and thus used for the present purpose). The parameter summaries at the top left of each graph show those mean parameter values---i.e., those are the parameters of the solid line.

```{r, fig.width=8, fig.height=16}
d.fitted = fit.lapse.mixed.mixture %>% 
  spread_draws(
    b_theta1_Intercept,
    b_mu2_Intercept,
    b_mu2_Size,
    b_mu2_ConditionCrowded.vs.Uncrowded,
    `b_mu2_Size:ConditionCrowded.vs.Uncrowded`,
    r_Subject__mu2[Subject, coef],
    r_Subject__theta1[Subject, coef2],
    n = 100) %>%
  pivot_wider(
    names_from = coef,
    values_from = r_Subject__mu2,
  ) %>%
  mutate(
    b_mu2_Intercept = b_mu2_Intercept + Intercept,
    b_mu2_Size = b_mu2_Size + Size,
    b_mu2_Condition = b_mu2_ConditionCrowded.vs.Uncrowded + Size,
    b_mu2_SizeCondition = `b_mu2_Size:ConditionCrowded.vs.Uncrowded` + Size,
    b_theta1_Intercept = b_theta1_Intercept + r_Subject__theta1
  ) %>%
  ungroup() %>%
  mutate_at("Subject", factor) %>%
  expand(
    nesting(
      .draw, 
      Subject,
      b_mu2_Intercept,
      b_mu2_Size,
      b_mu2_Condition,
      b_mu2_SizeCondition,
      b_theta1_Intercept),
    Size = seq(-2.5, 2.5, .1),
    Condition = c(-.5, .5),
  )

p = d.fitted %>%
  ggplot(aes(x = Size, color = Subject, linetype = as.factor(Condition))) +
  # individual lines
  geom_line(
    aes(
      y = inv_logit_scaled(
        b_mu2_Intercept + b_mu2_Condition * Condition + b_mu2_Size * Size + b_mu2_SizeCondition * Condition, 
        lb = .25, 
        ub = 1 - plogis(b_theta1_Intercept)),
      group = paste(Subject, Condition, .draw)),
    alpha = .1) +
  # by mean (solid) lines
  geom_line(
    data = . %>% 
      group_by(Subject, Size, Condition) %>%
      summarise(
        b_mu2_Intercept = mean(b_mu2_Intercept + b_mu2_Condition * Condition),
        b_mu2_Size = mean(b_mu2_Size + b_mu2_SizeCondition * Condition),
        b_theta1_Intercept = mean(plogis(b_theta1_Intercept))),
    aes(
      y = inv_logit_scaled(
        b_mu2_Intercept + b_mu2_Size * Size, 
        lb = .25, 
        ub = 1 - b_theta1_Intercept),
      group = paste(Subject, Condition)),
    size = 1.5) +
  scale_linetype(
    "Crowded", 
    breaks = c(-.5, .5),
    labels = c("no", "yes")) +
  theme_fivethirtyeight() +
  p.common + ylim(0,1)

ggsave(
  p +
    facet_grid(Subject ~ .),
  file = "../figures/lapsing-logistic-GLMM-bySubject.png",
       width = 8, height = 16)

p +
  geom_text(
    data = . %>% 
      group_by(Subject, Condition) %>%
      summarise(
        b_mu2_Intercept = mean(b_mu2_Intercept + b_mu2_Condition * Condition),
        b_mu2_Size = mean(b_mu2_Size + b_mu2_SizeCondition * Condition),
        b_theta1_Intercept = mean(plogis(b_theta1_Intercept))),
    x = -2.5, y = 1,
    hjust = 0,
    vjust = 1,
    size = 3,
    family = "Courier",
    fontface = "bold",
    color = "black",
    aes(
      group = paste(Subject, Condition),
      label = paste0(expression(eta), " = ", round(b_mu2_Intercept, 2), " + ", round(b_mu2_Size, 2), " * Size\n", 
                     expression(lambda), " = ", round(b_theta1_Intercept, 2)))) +
  facet_grid(Subject ~ Condition)

ggsave(
  file = "../figures/lapsing-logistic-GLMM-bySubjectCondition.png",
  width = 8, height = 16)
```


We can also visualize the joint posterior distribution of the model's three fixed effect parameters (and could do similarly for each subject). This reveals a correlation between the intercept and slope of the model:

```{r}
fit.lapse.mixed.mixture %>% 
  spread_draws(
    b_mu2_Intercept,
    b_mu2_Size,
    b_theta1_Intercept) %>%
  plotly::plot_ly(
    x = ~b_mu2_Intercept,
    y = ~b_mu2_Size,
    z = ~b_theta1_Intercept,
    alpha = .3
  )
```


# Weibull regression

The Weibull model is not a GLM, even if not combined with the lapse rate model. The Weibull has two parameters, the shape parameter $k$ and the scale parameter $\lambda$. Only if the shape parameter is known, is the remaining model a GLM (see \url{https://stats.stackexchange.com/questions/277466/is-weibull-distribution-a-exponential-family}).


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$Weibull$}} {} {}; %
    \node[det, right=of distribution] (shape) {$k$} ; %
    \node[det, above=of distribution] (mu) {$\lambda_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$log^{-1} = exp$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome) } {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu, shape} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{only scale parameter ($\lambda$) is inferred}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
  \tikz{ %
    \node[obs] (outcome) {$y_i$} ; %
    \factor[above=of outcome] {distribution} {left: \textcolor{orange}{$Weibull$}} {} {}; %
    \node[latent, right=of distribution] (shape) {$k$} ; %
    \node[det, above=of distribution] (mu) {$\lambda_i$} ; %
    \factor[above=of mu] {link} {left: \textcolor{blue}{$log^{-1} = exp$}} {} {}; %
    \node[obs, above=of link] (X) {$x_i$} ; %
    \node[latent, right=of X] (beta) {$\beta$} ; %
    % plates
    \plate[inner sep=0.12cm, xshift=-0.06cm, yshift=0.06cm] {plate1} {(mu) (distribution) (link) (X) (outcome) } {$\forall i=1 \ldots N $}; %
    \edge {distribution} {outcome} ; %
    \edge {mu, shape} {distribution} ; %
    \edge {link} {mu} ; %
    \edge {X, beta} {link} ; %
  }
  \caption{both shape ($k$ and scale parameters ($\lambda$) are inferred}
  \end{subfigure}
  \caption{The Weibull regression is {\em not} a GLM, unless the shape parameter $k$ is fixed (a). The Weibull model with both its scale and shape parameter can thus be seen as an infinite set of GLMs.}
\end{figure}

```{r, message=F, warning=F, error=F}
# This does not run since the Weibull is only defined over counts. 
# It might work if the data is converted into a count representation but I need to understand this better first.

# fit_mix.weibull <- brm(
#   bf(ResponseCorrect ~ 1, 
#      mu1 ~ 0 + offset(qlogis(.25)),
#      mu2 ~ 1 + Size * Condition + (1 + Size * Condition | Subject), 
#      theta1 ~ 1 + (1 | Subject)),
#   data = d, 
#   family = mixture(bernoulli("logit"), weibull("log"), order = "none"),
#   init = 0,
#   control = list(adapt_delta = 0.999),
#   iter = 2000,
#   thin = 1,
#   prior = my.priors.lapse.mixture,
#   file = "../models/subject-lapse-mixed-mixture-weibull")
```

# Appendix

## NLMM formulation of the lasping mixed-effect logistic model

An example of the NLMM specification of the mixed-effects logistic model, but without crowdedness condition or its interaction with letter size since even this simplified model did not converge. (I first took this approach and then switched to the mixture formulation presented above.)

```{r, echo=T}
BF.lapse.mixed <- brmsformula(
  # reparameterizing the model by fitting lapses in log-odds space (in order to aid convergence)
  # this means we need to convert the lapses back into proportion space below.
  ResponseCorrect ~ .25 + (.75-inv_logit(lapse)) * inv_logit(eta),
  eta ~ 1 + Size + (1 + Size | Subject),
  lapse ~ 1 + (1 | Subject), 
  family = bernoulli(link="identity"),
  nl = TRUE
)
```

```{r, message=F, warning=T, error=F}
my.priors.lapse <- c(
  prior(student_t(3, 0, 2.5), class = "b", nlpar = "eta"),
  prior(student_t(3, 0, 2.5), class = "b", nlpar = "lapse"),
  prior(cauchy(0,2.5), class = "sd", nlpar = "eta"),
  prior(cauchy(0,2.5), class = "sd", nlpar = "lapse")
)

fit.lapse.mixed <- brm(
  BF.lapse.mixed,
  data = d,
  init = 0,
  control = list(adapt_delta = 0.999),
  iter = 8000,
  thin = 5,
  prior = my.priors.lapse,
  file = "../models/subject-lapse-mixed-logit"
)

summary(fit.lapse.mixed)
```

The following plots shows the predictions for each of 100 random posterior samples from each subjects (each curve corresponds to one posterior sample). The solid lines shows the predictions based on the *means* of the posterior samples. The reason this line does not always fall in the center of the other lines is that the three parameters of the model can be correlated (within and across participants). Taking the mean, rather than marginalizing over the entire posterior distribution, ignores those correlations (but is a *lot* faster to compute and thus used for the present purpose). The parameter summaries at the top left of each graph show those mean parameter values---i.e., those are the parameters of the solid line.


```{r, fig.width=8, fig.height=16}
d.fitted = fit.lapse.mixed %>% 
  spread_draws(
    b_eta_Intercept,
    b_eta_Size,
    b_lapse_Intercept,
    r_Subject__eta[Subject, coef],
    r_Subject__lapse[Subject, coef2],
    n = 100) %>%
  pivot_wider(
    names_from = coef,
    values_from = r_Subject__eta,
  ) %>%
  mutate(
    b_eta_Intercept = b_eta_Intercept + Intercept,
    b_eta_Size = b_eta_Size + Size,
    b_lapse_Intercept = b_lapse_Intercept + r_Subject__lapse
  ) %>%
  ungroup() %>%
  mutate_at("Subject", factor) %>%
  expand(
    nesting(
      .draw, 
      Subject,
      b_eta_Intercept,
      b_eta_Size,
      b_lapse_Intercept),
    Size = seq(-2.5, 2.5, .1)
  )

d.fitted %>%
  ggplot(aes(x = Size, color = Subject)) +
  geom_line(
    aes(
      y = inv_logit_scaled(
        b_eta_Intercept + b_eta_Size * Size, 
        lb = .25, 
        ub = 1 - plogis(b_lapse_Intercept)),
      group = paste(Subject, .draw)),
    alpha = .1) +
  geom_line(
    data = . %>% 
      group_by(Subject, Size) %>%
      summarise(
        b_eta_Intercept = mean(b_eta_Intercept),
        b_eta_Size = mean(b_eta_Size),
        b_lapse_Intercept = mean(plogis(b_lapse_Intercept))),
    aes(
      y = inv_logit_scaled(
        b_eta_Intercept + b_eta_Size * Size, 
        lb = .25, 
        ub = 1 - b_lapse_Intercept),
      group = Subject),
    size = 1) +
  geom_text(
    data = . %>% 
      group_by(Subject) %>%
      summarise(
        b_eta_Intercept = mean(b_eta_Intercept),
        b_eta_Size = mean(b_eta_Size),
        b_lapse_Intercept = mean(plogis(b_lapse_Intercept))),
    x = -2.5, y = 1,
    hjust = 0,
    vjust = 1,
    size = 3,
    family = "Courier",
    fontface = "bold",
    color = "black",
    aes(
      group = Subject,
      label = paste0(expression(eta), " = ", round(b_eta_Intercept, 2), " + ", round(b_eta_Size, 2), " * Size\n", 
                     expression(lambda), " = ", round(b_lapse_Intercept, 2)))) +
  facet_wrap(~ Subject, nrow = 4) +
  theme_fivethirtyeight() +
  p.common + ylim(0,1)

# PS: a neat post on how to combine math expressions, variable values, and normal text in R:
# https://trinkerrstuff.wordpress.com/2018/03/15/2246/
```

And the joint posterior distribution of the model's three fixed effect parameters (and could do similarly for each subject). This reveals a correlation between the intercept and slope of the model:

```{r}
fit.lapse.mixed %>% 
  spread_draws(
    b_eta_Intercept,
    b_eta_Size,
    b_lapse_Intercept) %>%
  plotly::plot_ly(
    x = ~b_eta_Intercept,
    y = ~b_eta_Size,
    z = ~b_lapse_Intercept,
    alpha = .5
  )
```


# Session info
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
